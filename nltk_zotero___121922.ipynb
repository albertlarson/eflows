{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6f4ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from pyzotero import zotero\n",
    "import numpy as np\n",
    "import collections\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "def write(x,y):\n",
    "    with open(x,'a') as f:\n",
    "        f.write(y)\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e6c37e8b-b883-47ad-98cf-a90c19312595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "871f5b8b-04ea-46a7-baed-c9fc2fe27e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# itz[90]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a34d3a43-5eb4-40f7-a9db-047d12468bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in itz:\n",
    "#     print(i['data']['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bcc3bdac-d3d8-4ae4-ac88-3e770cbb2601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "1/20\n",
      "Evaluation of five instream flow needs methodologies and water quantity needs of three Utah trout streams\n",
      "1980\n",
      "\n",
      "Geer \n",
      "\n",
      "______\n",
      "\n",
      "2/20\n",
      "Environmental water requirements for lowland river systems on the Swan Coastal Plain\n",
      "1996\n",
      "\n",
      "\n",
      "Davies \n",
      "\n",
      "______\n",
      "\n",
      "3/20\n",
      "The basic flow: an alternative approach to calculate minimum environmental instream flows\n",
      "1996\n",
      "\n",
      "\n",
      "Palau \n",
      "\n",
      "______\n",
      "\n",
      "4/20\n",
      "River Allen instream flow requirements\n",
      "1993\n",
      "\n",
      "Johnson \n",
      "\n",
      "______\n",
      "\n",
      "5/20\n",
      "Report on minimum flow requirements for instream habitat in Taranaki rivers\n",
      "1993\n",
      "\n",
      "Jowett \n",
      "\n",
      "______\n",
      "\n",
      "6/20\n",
      "Flow regime requirements River Darent\n",
      "1993\n",
      "https://nora.nerc.ac.uk/id/eprint/508354/\n",
      "Ladle \n",
      "\n",
      "______\n",
      "\n",
      "7/20\n",
      "A preliminary assessment of the relationship between angling quality and flow on the Lower Malmesbury Avon\n",
      "1998\n",
      "\n",
      "\n",
      "Ibbotson \n",
      "\n",
      "______\n",
      "\n",
      "8/20\n",
      "Responses of biofilms to cyclic releases during a low flow period in the Mitta Mitta River, Victoria, Australia\n",
      "2006\n",
      "\n",
      "\n",
      "Watts \n",
      "\n",
      "______\n",
      "\n",
      "9/20\n",
      "Hydrologic Manipulations of the Channelized Kissimmee River: Implications for restoration\n",
      "1998-09-01\n",
      "10.2307/1313338\n",
      "https://doi.org/10.2307/1313338\n",
      "Toth \n",
      "\n",
      "______\n",
      "\n",
      "10/20\n",
      "Environmental flow requirements of the Brisbane River downstream from Wivenhoe Dam\n",
      "2000\n",
      "\n",
      "\n",
      "Arthington \n",
      "\n",
      "______\n",
      "\n",
      "11/20\n",
      "Field testing and adaptation of a methodology to measure \"in-stream\" values in the Tongue River, Northern Great Plains(NGP) region: executive summary\n",
      "1977\n",
      "https://nepis.epa.gov/Exe/ZyNET.exe/94000MM7.txt?ZyActionD=ZyDocument&Client=EPA&Index=1976%20Thru%201980&Docs=&Query=&Time=&EndTime=&SearchMethod=1&TocRestrict=n&Toc=&TocEntry=&QField=&QFieldYear=&QFieldMonth=&QFieldDay=&UseQField=&IntQFieldOp=0&ExtQFieldOp=0&XmlQuery=&File=D%3A%5CZYFILES%5CINDEX%20DATA%5C76THRU80%5CTXT%5C00000038%5C94000MM7.txt&User=ANONYMOUS&Password=anonymous&SortMethod=h%7C-&MaximumDocuments=1&FuzzyDegree=0&ImageQuality=r75g8/r75g8/x150y150g16/i425&Display=hpfr&DefSeekPage=x&SearchBack=ZyActionL&Back=ZyActionS&BackDesc=Results%20page&MaximumPages=1&ZyEntry=4#\n",
      "Bovee \n",
      "\n",
      "______\n",
      "\n",
      "12/20\n",
      "The use of benthic invertebrate production for the definition of Ecologically Acceptable Flows in\n",
      "2001\n",
      "\n",
      "\n",
      "Buffagni \n",
      "\n",
      "______\n",
      "\n",
      "13/20\n",
      "Instream flow requirements of aquatic ecology in two British rivers: application and assessment of the instream flow incremental methodology using the PHABSIM system\n",
      "1991\n",
      "\n",
      "Bullock \n",
      "\n",
      "______\n",
      "\n",
      "14/20\n",
      "Report of the Broken River Scientific Panel on the environmental condition and flows of the Broken River and Broken Creek\n",
      "2001\n",
      "https://ewater.org.au/archive/crcfe/freshwater/publications.nsf/8116917c22b76d58ca256f120027bb83/4164369b846ce43fca256f0b00217c4a02ec.html?OpenDocument\n",
      "Cotthingham \n",
      "\n",
      "______\n",
      "\n",
      "15/20\n",
      "Minimum acceptable stream flows in British Columbia: a review\n",
      "1977\n",
      "\n",
      "Neuman \n",
      "\n",
      "______\n",
      "\n",
      "16/20\n",
      "Evaluation of instream flow methods and determination of water quantity needs for streams in the state of Colorado\n",
      "1979\n",
      "\n",
      "Nehring \n",
      "\n",
      "______\n",
      "\n",
      "17/20\n",
      "Application of the Instream Flow Incremental Methodology to conservation flow for freshwater fishes in Japan\n",
      "1996\n",
      "\n",
      "\n",
      "Tamai \n",
      "\n",
      "______\n",
      "\n",
      "18/20\n",
      "Opihi catchment ecological flow assessment - Google Search\n",
      "\n",
      "https://www.google.com/search?q=Opihi+catchment+ecological+flow+assessment&client=firefox-b-d&sxsrf=ALiCzsbeWrvCS5PoWsVKX1yM4vKn98MZoQ%3A1669646327754&ei=98eEY-jULfCxptQPyN6N8Ag&ved=0ahUKEwiorJCijdH7AhXwmIkEHUhvA44Q4dUDCA4&uact=5&oq=Opihi+catchment+ecological+flow+assessment&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAUoECEYYAFAAWABg0QxoA3AAeACAAQCIAQCSAQCYAQCgAQLAAQE&sclient=gws-wiz-serp\n",
      "______\n",
      "\n",
      "19/20\n",
      "Flow recommendations for the tributaries of the Great Lakes in New York and Pennsylvania\n",
      "2013\n",
      "\n",
      "\n",
      "Taylor \n",
      "\n",
      "______\n",
      "\n",
      "20/20\n",
      "Development of recommended flow targets to support biological integrity based on regional flow-ecology relationships for benthic macroinvertebrates in Southern California streams\n",
      "2017\n",
      "\n",
      "\n",
      "Stein \n",
      "\n",
      "______\n",
      "\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "### use this to configure with your own api key and groupnum.\n",
    "###  https://pyzotero.readthedocs.io/en/latest/#getting-started-short-version\n",
    "\n",
    "personal_id = 7070461\n",
    "# group_id = 4842799\n",
    "api_key = 'mRPNA1Ix2bVhtm7TBgpakNBB'\n",
    "\n",
    "zot = zotero.Zotero(personal_id,'user',api_key)\n",
    "cols = zot.collections()\n",
    "\n",
    "# itz = zot.everything(zot.collection_items(cols[-1]['key'])) \n",
    "#not helpful here, includes multiple entries of same\n",
    "\n",
    "itz = zot.everything(zot.collection_items_top(cols[0]['key']))\n",
    "print(len(itz))\n",
    "\n",
    "coun = 0\n",
    "for idx,i in enumerate(itz):\n",
    "    x = len(i['data']['abstractNote'])\n",
    "    if x < 100:\n",
    "        coun += 1\n",
    "\n",
    "count = 0\n",
    "for idx,i in enumerate(itz):\n",
    "    x = len(i['data']['abstractNote'])\n",
    "    if x < 100:\n",
    "        count += 1\n",
    "        print(f\"{count}/{coun}\")\n",
    "        print(i['data']['title'])\n",
    "        # print(i['data']['auth\n",
    "        print(i['data']['date'])\n",
    "        try:\n",
    "            print(i['data']['DOI'])\n",
    "        except:\n",
    "            _\n",
    "        try:\n",
    "            print(i['data']['url'])\n",
    "        except:\n",
    "            _\n",
    "        try:\n",
    "            print(i['data']['creators'][0]['lastName'],'\\n')\n",
    "        except:\n",
    "            _\n",
    "        print('______\\n')\n",
    "print(coun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8f55c911-8e00-4215-b8cb-e1aea5d4adee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 3)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = []\n",
    "for idx,_ in enumerate(range(len(itz))):\n",
    "    x = itz[idx]['data']['title']\n",
    "    y = itz[idx]['data']['abstractNote']\n",
    "    z = [i['tag'] for i in itz[idx]['data']['tags']]\n",
    "    # try:\n",
    "    #     a = itz[idx]['data']['DOI']\n",
    "    #     if len(a) == 0:\n",
    "    #         a = 'no doi'\n",
    "    # except:\n",
    "    #     a = 'no doi'\n",
    "    # b = itz[idx]['data']['date']\n",
    "    \n",
    "    A.append([x,y,z])   \n",
    "A = np.asarray(A,dtype=object)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2234ab74-4868-49de-a15a-556ff5e2dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count0 = collections.Counter()\n",
    "for idx,i in enumerate(A[:,0]):\n",
    "    s1 = i.replace(\"'\", '')\n",
    "    s2 = s1.replace(\"?\", '')\n",
    "    s3 = s2.replace(\".\",'')\n",
    "    s4 = s3.replace(\",\",'')\n",
    "    s5 = s4.replace(\":\",'')\n",
    "    s6 = s5.lower()\n",
    "    tokens = nltk.word_tokenize(s6)\n",
    "    every = nltk.everygrams(tokens,2,4)\n",
    "    count0 = count0 + (collections.Counter(every))\n",
    "count0 = count0.most_common()\n",
    "\n",
    "count1 = collections.Counter()\n",
    "for idx, i in enumerate(A[:,1]):\n",
    "    s1 = i.replace(\"'\", '')\n",
    "    s2 = s1.replace(\"?\", '')\n",
    "    s3 = s2.replace(\".\",'')\n",
    "    s4 = s3.replace(\",\",'')\n",
    "    s5 = s4.replace(\":\",'')\n",
    "    s6 = s5.lower()\n",
    "    tokens = nltk.word_tokenize(s6)\n",
    "    every = nltk.everygrams(tokens,2,4)\n",
    "    count1 = count1 + (collections.Counter(every))\n",
    "count1 = count1.most_common()\n",
    "\n",
    "count2 = collections.Counter()\n",
    "for idx, i in enumerate(A[:,2]):\n",
    "    x = collections.Counter([l.lower() for l in i])\n",
    "    count2 += x\n",
    "count2 = count2.most_common()\n",
    "\n",
    "\n",
    "\n",
    "count3 = count0 + count1 + count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "521093e2-08eb-4897-8c38-272444858956",
   "metadata": {},
   "outputs": [],
   "source": [
    "badwords = ['the','in','a','of','for','and','an','to']\n",
    "count4 = []\n",
    "for idx,i in enumerate(count3):\n",
    "    coun = 0\n",
    "    for idj,j in enumerate(i[0]):\n",
    "        if j in badwords:\n",
    "            break\n",
    "        else:\n",
    "            coun+=1\n",
    "    if coun == len(i[0]):\n",
    "        count4.append(i)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "34094ea1-897d-47a8-8bb6-804cf0476a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('environmental', 'flow'), 48),\n",
       " (('environmental', 'flows'), 42),\n",
       " (('river', 'basin'), 14),\n",
       " (('instream', 'flow'), 14),\n",
       " (('case', 'study'), 12),\n",
       " (('flow', 'regimes'), 12),\n",
       " (('flow', 'regime'), 11),\n",
       " (('flow', 'requirements'), 11),\n",
       " (('environmental', 'water'), 7),\n",
       " (('flow', 'assessment'), 6),\n",
       " (('hydrologic', 'alteration'), 5),\n",
       " (('environmental', 'flow', 'requirements'), 5),\n",
       " (('environmental', 'flow', 'regimes'), 5),\n",
       " (('environmental', 'flow', 'assessment'), 5),\n",
       " (('flow–ecology', 'relationships'), 5),\n",
       " (('regional', 'scale'), 4),\n",
       " (('natural', 'flow'), 4),\n",
       " (('flow', 'management'), 4),\n",
       " (('victoria', 'australia'), 4),\n",
       " (('incremental', 'methodology'), 4),\n",
       " (('flow', 'needs'), 4),\n",
       " (('minimum', 'environmental'), 4),\n",
       " (('instream', 'flow', 'requirements'), 4),\n",
       " (('minimum', 'flow'), 4),\n",
       " (('ecological', 'flow'), 4),\n",
       " (('fish', 'species'), 4),\n",
       " (('water', 'management'), 4),\n",
       " (('eloha', 'framework'), 3),\n",
       " (('flow-ecology', 'relationships'), 3),\n",
       " (('determining', 'environmental'), 3)]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count4[:30]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
