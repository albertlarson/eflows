{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03f2060c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyzotero'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3844\\4109249281.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyzotero\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzotero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#Info: tags from WoS https://images.webofknowledge.com/images/help/WOS/hs_wos_fieldtags.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyzotero'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from inspect import getsourcefile\n",
    "import litstudy #Use pip install git+https://github.com/NLeSC/litstudy to download dev version. Other encoding problem when loading ris files (load_ris_file needs to use robust_open instead of open)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "import shutil\n",
    "from pyzotero import zotero\n",
    "\n",
    "#Info: tags from WoS https://images.webofknowledge.com/images/help/WOS/hs_wos_fieldtags.html\n",
    "\n",
    "#Set up project directory structure\n",
    "rootdir = os.path.dirname(os.getcwd())\n",
    "scopdir = Path(rootdir, \"data\", \"scoping\")\n",
    "resdir = Path(rootdir, \"results\")\n",
    "srcdir = Path(rootdir, 'src')\n",
    "\n",
    "#Subdirectory where tab-delimited files of wos outputs were saved\n",
    "scoping_3_datdir = Path(scopdir, 'scoping_3_wos')\n",
    "\n",
    "#Pickle were loaded data will be saved\n",
    "scoping_3_docset_pickle = Path(scoping_3_datdir, 'scoping_3_docset.pickle') \n",
    "\n",
    "#csv table where references' title, journal, year and DOI are written\n",
    "reflist_csv = Path(scoping_3_datdir, 'scoping_3_shortmetadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0c21725a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~ Read and compile references from the WoS search ~~~~~~~~~~~~~~~~~~\n",
    "#into a single document set (lit_study format)\n",
    "\n",
    "if not scoping_3_docset_pickle.exists():\n",
    "    #Get list of every bib file\n",
    "    bib_initlist = [p for p in list(scoping_3_datdir.glob('*')) \n",
    "                    if re.compile(\".*savedrecs(\\([0-9]{1,2}\\))*[.]bib\").match(str(p))]\n",
    "    #Read bib files from first scoping and join them (takes ~15-20 sec/1000 refs)\n",
    "    reflist = []\n",
    "    for bib in bib_initlist:\n",
    "        reflist += litstudy.load_bibtex(bib)\n",
    "    \n",
    "    #Pickle them (save the full document set as a binary file on disk that can be easily retrieved)\n",
    "    with open(scoping_3_docset_pickle, 'wb') as f:\n",
    "        pickle.dump(reflist, f)\n",
    "else:\n",
    "    #Read pre-saved document set\n",
    "    with open(scoping_3_docset_pickle, 'rb') as f:\n",
    "        reflist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c2363eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4f369bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~ Get titles and DOIs from test list ~~~~~~~~~~~~~~~\n",
    "api_key = Path(srcdir, 'zotero_key.txt').read_text().strip()\n",
    "zot = zotero.Zotero(library_id = '4842799', library_type = 'group', api_key = api_key)\n",
    "testlist_colID = str([col['key'] for col in zot.collections_top()\n",
    "                      if col['data']['name'] == 'test list'][0])\n",
    "testlist_items = zot.everything(zot.collection_items_top(testlist_colID))\n",
    "\n",
    "testlist_title_dois = defaultdict(list)\n",
    "for ref in testlist_items:\n",
    "    testlist_title_dois[ref['key']].append(ref['data']['title'])\n",
    "    if 'DOI' in ref['data']:\n",
    "        testlist_title_dois[ref['key']].append(ref['data']['DOI'])\n",
    "    else:\n",
    "        testlist_title_dois[ref['key']].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a0189ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~ Write basic metadata from reference list to csv ~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "#Get all dois and titles in references returned from search\n",
    "if not reflist_csv.exists():\n",
    "    reflist_dict = {}\n",
    "    for i, ref in enumerate(reflist):\n",
    "        reflist_dict[i] = [ref.title.replace('\\n', ' ').lower(), ref.publication_source, ref.publication_year]\n",
    "        if 'doi' in ref.entry:\n",
    "            reflist_dict[i].append(ref.entry['doi'])\n",
    "        else:\n",
    "            reflist_dict[i].append(np.nan)\n",
    "\n",
    "    reflist_pd = pd.DataFrame.from_dict(reflist_dict, orient='index')\n",
    "    reflist_pd.columns = ['title', 'source', 'year', 'doi']\n",
    "    \n",
    "    reflist_pd.to_csv(reflist_csv)\n",
    "else:\n",
    "    reflist_pd = pd.read_csv(reflist_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "078c4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~ Check which items in test list were retrieved through the search ~~~~~~~\n",
    "returned = {}\n",
    "not_returned = {}\n",
    "\n",
    "for k, v in testlist_title_dois.items():\n",
    "    if (v[0].lower() in set(reflist_pd.title)) or (v[1] in set(reflist_pd.doi)):\n",
    "        returned[k] = v[0]\n",
    "    else:\n",
    "        not_returned[k] = v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c784c465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NQE4IR8E': 'Development of recommended flow targets to support biological integrity based on regional flow-ecology relationships for benthic macroinvertebrates in Southern California streams',\n",
       " '6D7DKZTE': 'Flow recommendations for the tributaries of the Great Lakes in New York and Pennsylvania',\n",
       " 'BD4MS6ET': 'Application of the Instream Flow Incremental Methodology to conservation flow for freshwater fishes in Japan',\n",
       " 'MRZD6NI7': 'Environmental flow requirements of the Brisbane River downstream from Wivenhoe Dam',\n",
       " 'VA65CY5L': 'Responses of biofilms to cyclic releases during a low flow period in the Mitta Mitta River, Victoria, Australia',\n",
       " 'FZ78KPH2': 'A preliminary assessment of the relationship between angling quality and flow on the Lower Malmesbury Avon',\n",
       " 'E5GD6SBW': 'Evaluation of instream flow methodologies for fisheries in Nebraska',\n",
       " '5ABFNPLW': 'Effects of experimental ramping rate of invertebrate community of a regulated river',\n",
       " '78R3U4TV': 'Evaluating fine sediment mobilization and storage in a gravel‐bed river using controlled reservoir releases',\n",
       " '8LLPFL3Q': 'Some Environmental Aspects of the Management of Water Supplies for the Region of Madrid - CUBILLO - 1992 - Water and Environment Journal - Wiley Online Library',\n",
       " '5PGV6BW2': 'Flow management to sustain groundwater‐dominated stream ecosystems',\n",
       " 'FBNIZFMX': 'Flow-recruitment relationships for Shoal Chub (Macrhybopsis hyostoma) and implications for managing environmental flows',\n",
       " '8MGJSV6Q': 'Summary of environmental flow monitoring for the Sustainable Rivers Project on the Middle Fork Willamette and McKenzie Rivers, western Oregon, 2014–15',\n",
       " 'N82RHBFN': 'Instream-flow analysis for the Luquillo Experimental Forest, Puerto Rico: methods and analysis',\n",
       " 'XXWDW65Y': 'The basic flow: an alternative approach to calculate minimum environmental instream flows',\n",
       " 'QSA6R86M': 'The Applicability of Instream Flow Incremental Methodology for Impact Assessment in Newfoundland',\n",
       " 'TPANMNII': 'Environmental water requirements for lowland river systems on the Swan Coastal Plain',\n",
       " 'KF78K6WX': 'Comparison of discharge methods and habitat optimization for recommending instream flows to protect fish habitat',\n",
       " 'TYVPCM8G': 'Review of Determination of Instream Flow Requirements with Special Application to Australia1',\n",
       " 'J7CLJCLB': 'Relative Bias of Several Fisheries Instream Flow Methods',\n",
       " 'RXDXNHDD': 'Enhancement of benthic macroinvertebrates by minimum flow from a hydroelectric dam',\n",
       " 'BC3K6KT3': 'Enhancement of Fish Feeding and Growth after an Increase in Minimum Flow below the Conowingo Dam',\n",
       " 'Q3VVEKRA': 'Hydrologic Manipulations of the Channelized Kissimmee River: Implications for restoration',\n",
       " 'EG3LUY86': 'Small environmental flows, drought and the role of refugia for freshwater fish in the Macquarie Marshes, arid Australia',\n",
       " 'FM669F58': 'Estimating Minimum Instream Flow Requirements for Minnesota Streams from Hydrologic Data and Watershed Characteristics',\n",
       " 'GK9XDHS5': 'Effects of instream enhancement structures on brown trout, Salmo trutta L., habitat availability in a channelized boreal river: a PHABSIM approach',\n",
       " 'YTVMZ36Z': 'History, rationale, and lessons learned: Thresholds of potential concern in Kruger National Park river adaptive management',\n",
       " 'GL2SRL5H': 'Mapping hydrologic alteration and ecological consequences in stream reaches of the conterminous United States',\n",
       " 'ND4ASPRW': 'New integrated hydrologic approach for the assessment of rivers environmental flows into the Urmia Lake',\n",
       " 'I2BLKHVN': 'Measuring and evaluating ecological flows from streams to regions: Steps towards national coverage',\n",
       " '2DJR9MEH': 'Integrated Procedure for Environmental Flow Assessment in Rivers',\n",
       " 'TPWAN3HY': 'Evidence of population resistance to extreme low flows in a fluvial-dependent fish species',\n",
       " 'F7TT8TMV': 'Designing river flows to improve food security futures in the Lower Mekong Basin.',\n",
       " 'CW22K69W': 'Designing flows to resolve human and environmental water needs in a dam-regulated river',\n",
       " 'J4IPA7ZT': 'Environmental Flow Assessment Using Water-Sediment Approach at the Sekampung River, Indonesia',\n",
       " 'NBYJ5JU2': 'Predicting Salmonid Habitat–Flow Relationships for Streams from Western North America',\n",
       " '9WNWDU83': 'Generalized models of riverine fish hydraulic habitat'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22fd3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Compare results to test list \n",
    "# - Sample X% of returns to assess specificity and sensitivity with preliminary eligibility criteria \n",
    "# - (for scopus and OpenAlex): for each retrieved article, identify articles with search terms that retrieved them. THis will allow us to remove search terms that are 100% redundant and to identify those that lead to low specificity \n",
    "# - Individually investigate why article from test list was not retrieved so that the search strategy can be adjusted \n",
    "# - Go through 100 articles for each database simply to test sensitivity of each database (because OpenAlex, WoS, Scopus and GS rely on such different algorithms and searching strategies) and refine strings if needed for each. Each one of us will screen 75 of these articles for each database with 50 articles in common for each database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26031400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Extra stuff for ris\n",
    "#Remove total times cited and cited reference count lines, as well as line breaks within tags\n",
    "#for each citation because it crashes litstudy\n",
    "ris_initlist_edit = []\n",
    "for ris in ris_initlist:\n",
    "    ris_edit = Path(f\"{ris.with_suffix('')}_edit.ris\")\n",
    "    ris_initlist_edit.append(ris_edit)\n",
    "    if not ris_edit.exists():\n",
    "        with open(ris, 'r', encoding='utf-8') as f_in:\n",
    "            ris_txt = f_in.read()\n",
    "        ris_txt_edit = re.sub('(Total Times Cited:\\\\s\\\\s[0-9]*\\nCited Reference Count:\\\\s\\\\s[0-9]*\\n)|(\\n\\\\s)',\n",
    "                              '', ris_txt)   \n",
    "        \n",
    "        with open(ris_edit, 'w', encoding='utf-8') as f_out:\n",
    "            f_out.write(ris_txt_edit)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
